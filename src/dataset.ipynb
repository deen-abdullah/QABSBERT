{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset.ipynb","provenance":[],"toc_visible":true,"mount_file_id":"1E841bnzl0Vt2WikS2pXa6R5fVCWGRwVi","authorship_tag":"ABX9TyN4YE2fMnhSqE5//w32mL8A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xAeKkv0lIQ50"},"source":["Some codes are collected from the work of [Liu and Lapata](https://arxiv.org/abs/1908.08345)\r\n","\r\n","## **CNN/DailyMail Dataset Preparation**\r\n","\r\n","**Step 1 Download Stories:** Download and unzip the stories directories from [here](https://cs.nyu.edu/~kcho/DMQA/) for both CNN and Daily Mail. Put all .story files in one directory (e.g. ../raw_stories)"]},{"cell_type":"code","metadata":{"id":"CL-s8Z4VINMN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609084749952,"user_tz":420,"elapsed":6735,"user":{"displayName":"Deen Mohammad Abdullah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-3YbbwiR8EKv7nSyKqX8qvhqUVXrdMV8ZWVbjSg=s64","userId":"11083323856632170809"}},"outputId":"5246e27f-6305-40d2-ff6e-686bf1de0d3c"},"source":["#!pip install pytorch-transformers\r\n","\r\n","#%cd\r\n","#%cd ../content/drive/MyDrive/ColabNotebooks\r\n","#!git clone https://github.com/bheinzerling/pyrouge\r\n","#%cd pyrouge\r\n","#!pip install -e .\r\n","#!git clone https://github.com/andersjo/pyrouge.git rouge\r\n","#%cd\r\n","#%cd ../content\r\n","#%cd drive/MyDrive/ColabNotebooks/DatasetPreparation/src\r\n","#!pyrouge_set_rouge_path ../../pyrouge/rouge/tools/ROUGE-1.5.5/\r\n","#%cd ../../pyrouge/rouge/tools/ROUGE-1.5.5/data\r\n","\r\n","#!pip install -U spacy\r\n","#!python3 -m spacy download en_core_web_md\r\n","\r\n","'''\r\n","%cd\r\n","%cd ../content\r\n","%cd drive/MyDrive/ColabNotebooks/DatasetPreparation/src\r\n","!python preprocess.py -mode tokenize -raw_path ../raw_stories -save_path ../merged_stories_tokenized \r\n","'''\r\n"],"execution_count":74,"outputs":[{"output_type":"stream","text":["/root\n","/content\n","/content/drive/MyDrive/ColabNotebooks/DatasetPreparation/src\n","Preparing to tokenize /content/drive/MyDrive/ColabNotebooks/DatasetPreparation/raw_stories to /content/drive/MyDrive/ColabNotebooks/DatasetPreparation/merged_stories_tokenized...\n","Making list of files to tokenize...\n","Tokenizing 5 files in /content/drive/MyDrive/ColabNotebooks/DatasetPreparation/raw_stories and saving in /content/drive/MyDrive/ColabNotebooks/DatasetPreparation/merged_stories_tokenized...\n","Error: Could not find or load main class edu.stanford.nlp.pipeline.StanfordCoreNLP\n","Caused by: java.lang.ClassNotFoundException: edu.stanford.nlp.pipeline.StanfordCoreNLP\n","Stanford CoreNLP Tokenizer has finished.\n","Traceback (most recent call last):\n","  File \"preprocess.py\", line 73, in <module>\n","    eval('data_builder.'+args.mode + '(args)')\n","  File \"<string>\", line 1, in <module>\n","  File \"/content/drive/MyDrive/ColabNotebooks/DatasetPreparation/src/prepro/data_builder.py\", line 141, in tokenize\n","    tokenized_stories_dir, num_tokenized, stories_dir, num_orig))\n","Exception: The tokenized stories directory /content/drive/MyDrive/ColabNotebooks/DatasetPreparation/merged_stories_tokenized contains 0 files, but it should contain the same number as /content/drive/MyDrive/ColabNotebooks/DatasetPreparation/raw_stories (which has 5 files). Was there an error during tokenization?\n"],"name":"stdout"}]}]}